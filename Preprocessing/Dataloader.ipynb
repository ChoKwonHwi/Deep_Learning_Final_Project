{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir='./BraTs'\n",
    "all_dirs = glob (f'{imgs_dir}/*')\n",
    "len (all_dirs)\n",
    "all_dirs.sort()\n",
    "len(all_dirs), all_dirs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split (all_dirs, val_pct = 0.15, seed = 99):\n",
    "    \"\"\" shuffling dataset with random state and split to train and valid \"\"\"\n",
    "    n_val = int (len (all_dirs) * val_pct)\n",
    "    np.random.seed (seed)\n",
    "    idx = np.random.permutation (len (all_dirs))\n",
    "    all_dirs = np.array (all_dirs) [idx]\n",
    "    \n",
    "    return all_dirs [n_val:], all_dirs [:n_val]\n",
    "\n",
    "train_dirs, valid_dirs = shuffle_split (all_dirs, seed = 1)\n",
    "len(valid_dirs), len(train_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BratsDataset (Dataset):\n",
    "    def __init__ (self, img_dirs, modality_types, transform = None):\n",
    "        self.img_dirs = img_dirs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len (self.img_dirs)\n",
    "\n",
    "    def __getitem__ (self, index):\n",
    "        imgs_path = self.img_dirs [index]\n",
    "        image = self.concat_imgs (imgs_path)\n",
    "        mask = np.array (Image.open (f'{imgs_path}/seg.jpg'))\n",
    "        mask = (mask / 255 * 4).round ()\n",
    "        mask = self.preprocess_mask_labels(mask)\n",
    "        \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image = image, mask = mask)\n",
    "            image = augmented ['image']\n",
    "            mask = augmented ['mask']\n",
    "\n",
    "        return image.astype(float), mask.astype(float)\n",
    "\n",
    "    def concat_imgs (self, path: str):\n",
    "        types = []\n",
    "        for modality_type in modality_types:\n",
    "            img = np.array (Image.open (f'{path}/{modality_type}.jpg'))\n",
    "            img = self.normalize(img)\n",
    "            types.append (img)\n",
    "        return np.array(types)\n",
    "    \n",
    "    def preprocess_mask_labels(self, mask: np.ndarray):\n",
    "        mask_WT = np.zeros(mask.shape)\n",
    "        mask_WT[mask == 2] = 1\n",
    "       \n",
    "        mask_TC = np.zeros(mask.shape)\n",
    "        mask_TC[mask == 1] = 1\n",
    "\n",
    "        mask_ET = np.zeros(mask.shape)\n",
    "        mask_ET[mask == 3] = 1\n",
    "        \n",
    "        mask_BG = np.zeros(mask.shape)\n",
    "        mask_BG[mask == 0] = 1\n",
    "        \n",
    "        mask = np.stack([mask_WT, mask_TC, mask_ET, mask_BG])\n",
    "        # mask = np.moveaxis(mask, (0, 1, 2), (0, 2, 1))\n",
    "        return mask\n",
    "    \n",
    "    def normalize(self, data: np.ndarray):\n",
    "        data_min = np.min(data)\n",
    "        if np.max(data) == 0:\n",
    "            return data\n",
    "        if (np.max(data) - data_min) == 0:\n",
    "            return data / data_min \n",
    "        \n",
    "        return (data - data_min) / (np.max(data) - data_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation\n",
    "trn_tfms = A.Compose (\n",
    "[\n",
    "    A.Resize (height = 240, width = 240),\n",
    "         A.Rotate (limit = 35, p = 1.0),\n",
    "         A.HorizontalFlip (p = 0.5),\n",
    "         A.VerticalFlip (p = 0.1),\n",
    "         A.Normalize (mean=0.5, std=0.5, max_pixel_value = 255.0), \n",
    "             img = (img - mean * max_pixel_value) / (std * max_pixel_value)\n",
    "         ToTensorV2 ()\n",
    "])\n",
    "\n",
    "\n",
    "val_tfms = A.Compose (\n",
    "[\n",
    "    A.Resize (height = 240, width = 240),\n",
    "         A.Normalize (0.5, 0.5, max_pixel_value = 255.0),\n",
    "         ToTensorV2 ()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_types = ['flair', 't1', 't1ce', 't2']\n",
    "\n",
    "batch_size = 64  # 총 배치 사이즈\n",
    "\n",
    "train_ds = BratsDataset(train_dirs, modality_types)\n",
    "valid_ds = BratsDataset(valid_dirs, modality_types)\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = False, num_workers = 12, pin_memory = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = batch_size, shuffle = False, num_workers = 12, pin_memory = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlab",
   "language": "python",
   "name": "vlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
