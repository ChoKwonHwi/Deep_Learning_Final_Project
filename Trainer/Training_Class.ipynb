{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 net: nn.Module,\n",
    "                 train_dl: DataLoader,\n",
    "                 val_dl: DataLoader,\n",
    "                 criterion: nn.Module,\n",
    "                 lr: float,\n",
    "                 accumulation_steps: int,\n",
    "                 batch_size: int,\n",
    "                 num_epochs: int,\n",
    "                 display_plot: bool = True,\n",
    "                ):\n",
    "\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"device:\", self.device)\n",
    "        self.display_plot = display_plot\n",
    "        self.net = net\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = Adam(self.net.parameters(), lr=lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\",\n",
    "                                           patience=2, verbose=True)\n",
    "        self.accumulation_steps = accumulation_steps // batch_size\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.num_epochs = num_epochs\n",
    "        self.dataloaders = {\n",
    "            \"train\": train_dl,\n",
    "            \"val\"  : val_dl \n",
    "        }\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        self.jaccard_scores = {phase: [] for phase in self.phases}\n",
    "    \n",
    "    def _compute_loss_and_outputs(self, images: torch.Tensor, targets: torch.Tensor):\n",
    "        images = images.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "        outputs = self.net(images.float())\n",
    "\n",
    "        # UNet 모델이 튜플을 반환하는 경우 첫 번째 요소만 사용\n",
    "        logits = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "\n",
    "        loss = self.criterion(logits, targets)\n",
    "        return loss, logits    \n",
    "     \n",
    "    def _do_epoch(self, epoch: int, phase: str):\n",
    "        print(f\"{phase} epoch: {epoch} | time: {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "        self.net.train() if phase == \"train\" else self.net.eval()\n",
    "        meter = Meter()\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        total_batches = len(dataloader)\n",
    "        running_loss = 0.0\n",
    "        self.optimizer.zero_grad()\n",
    "        for itr, (images, targets) in enumerate(dataloader):\n",
    "            loss, logits = self._compute_loss_and_outputs(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            meter.update(logits.detach().cpu(),\n",
    "                         targets.detach().cpu()\n",
    "                        )\n",
    "            \n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        epoch_dice, epoch_iou = meter.get_metrics()\n",
    "                \n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(epoch_dice)\n",
    "        self.jaccard_scores[phase].append(epoch_iou)\n",
    "\n",
    "        return epoch_loss\n",
    "    \n",
    "    def run(self):\n",
    "            for epoch in range(self.num_epochs):\n",
    "                self._do_epoch(epoch, \"train\")\n",
    "            with torch.no_grad():\n",
    "                val_loss = self._do_epoch(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if self.display_plot:\n",
    "                self._plot_train_history()\n",
    "                \n",
    "            if val_loss < self.best_loss:\n",
    "                print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n",
    "                self.best_loss = val_loss\n",
    "                torch.save(self.net.module.state_dict(), \"best_model2.pth\")\n",
    "            print()\n",
    "            self._save_train_history()\n",
    "                \n",
    "    def _plot_train_history(self):\n",
    "        data = [self.losses, self.dice_scores, self.jaccard_scores]\n",
    "        colors = ['deepskyblue', \"crimson\"]\n",
    "        labels = [\n",
    "            f\"\"\"\n",
    "            train loss {self.losses['train'][-1]}\n",
    "            val loss {self.losses['val'][-1]}\n",
    "            \"\"\",\n",
    "            \n",
    "            f\"\"\"\n",
    "            train dice score {self.dice_scores['train'][-1]}\n",
    "            val dice score {self.dice_scores['val'][-1]} \n",
    "            \"\"\", \n",
    "                  \n",
    "            f\"\"\"\n",
    "            train jaccard score {self.jaccard_scores['train'][-1]}\n",
    "            val jaccard score {self.jaccard_scores['val'][-1]}\n",
    "            \"\"\",\n",
    "        ]\n",
    "            \n",
    "        from IPython.display import clear_output\n",
    "        clear_output(True)\n",
    "        plt.style.use('default')  # 기본 스타일 사용\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(8, 10))\n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.plot(data[i]['val'], c=colors[0], label=\"val\")\n",
    "            ax.plot(data[i]['train'], c=colors[-1], label=\"train\")\n",
    "            ax.set_title(labels[i])\n",
    "            ax.legend(loc=\"upper right\")\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "    def load_predtrain_model(self,\n",
    "                             state_path: str):\n",
    "        self.net.load_state_dict(torch.load(state_path))\n",
    "        print(\"Predtrain model loaded\")\n",
    "        \n",
    "    def _save_train_history(self):\n",
    "        \"\"\"writing model weights and training logs to files.\"\"\"\n",
    "        torch.save(self.net.module.state_dict(),\n",
    "                   f\"last_epoch_model.pth\")\n",
    "        logs_ = [self.losses, self.dice_scores, self.jaccard_scores]\n",
    "        log_names_ = [\"_loss\", \"_dice\", \"_jaccard\"]\n",
    "        logs = [logs_[i][key] for i in list(range(len(logs_)))\n",
    "                         for key in logs_[i]]\n",
    "        log_names = [key+log_names_[i] \n",
    "                     for i in list(range(len(logs_))) \n",
    "                     for key in logs_[i]\n",
    "                    ]\n",
    "        pd.DataFrame(\n",
    "            dict(zip(log_names, logs))\n",
    "        ).to_csv(\"train_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BratsDataset(train_dirs, modality_types)\n",
    "valid_ds = BratsDataset(valid_dirs, modality_types)\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = False, num_workers = 12, pin_memory = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = batch_size, shuffle = False, num_workers = 12, pin_memory = True)\n",
    "\n",
    "print(len(valid_dl ), len(train_dl))\n",
    "device = torch.device ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델 설정 및 DataParallel 적용\n",
    "model = UNet(n_channels=4, n_classes=4, bilinear=True).float()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlab",
   "language": "python",
   "name": "vlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
